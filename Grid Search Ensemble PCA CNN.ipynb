{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import tensordot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GL65\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"weather3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(trainX, trainY):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=True, input_shape=(4,1)))\n",
    "    model.add(LSTM(64, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "   \n",
    "    model.compile(loss='mse',\n",
    "                optimizer='adam',\n",
    "                metrics=['mae', 'mse'])\n",
    "    \n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    model.fit(trainX, trainY, epochs=1000, validation_split = 0.2, verbose=0, \n",
    "                    callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predictions(members, weights, testX):\n",
    "\n",
    "    yhats = [model.predict(testX) for model in members]\n",
    "    yhats = array(yhats)\n",
    "    summed = tensordot(yhats, weights, axes=((0),(0)))\n",
    "    return summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_r2(members, weights, testX, testY):\n",
    "\n",
    "    yhat = ensemble_predictions(members, weights, testX)\n",
    "    return r2_score(testY, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(weights):\n",
    "    result = norm(weights,1)\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    return weights / result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(members, testX, testY,n_members):\n",
    "\n",
    "    i =0;\n",
    "    w = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    best_score, best_weights = 0.0, None\n",
    "    for weights in product(w,repeat=len(members)):\n",
    "       \n",
    "        if len(set(weights)) == 1:\n",
    "            continue\n",
    "    \n",
    "        weights = normalize(weights)\n",
    "        score = evaluate_r2(members, weights, testX, testY)\n",
    "        if score > best_score:\n",
    "            best_score, best_weights = score, weights\n",
    "            print('>%s %.3f' % (best_weights, best_score))\n",
    "            i+=1\n",
    "        \n",
    "        if i == n_members+1:\n",
    "            break;\n",
    "            \n",
    "    return list(best_weights)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df.sample(frac=0.8,random_state=0)\n",
    "test_dataset = df.drop(train_dataset.index)\n",
    "    \n",
    "train_stats = train_dataset.describe()\n",
    "train_stats.pop(\"Solar Irradiance\")\n",
    "train_stats = train_stats.transpose()\n",
    "    \n",
    "train_labels = train_dataset.pop('Solar Irradiance')\n",
    "test_labels = test_dataset.pop('Solar Irradiance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm1(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "normed_train_data = norm1(train_dataset)\n",
    "normed_test_data = norm1(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final= normed_train_data.values\n",
    "test_final = normed_test_data.values\n",
    "train=train_labels.values\n",
    "test=test_labels.values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(.95)\n",
    "pca.fit(train_final)\n",
    "    \n",
    "pca_train = pca.transform(train_final)\n",
    "pca_test = pca.transform(test_final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(pca_train, axis=2)\n",
    "X_test = np.expand_dims(pca_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, loss:206966.0000,  mae:341.3239,  mse:206966.0000,  val_loss:42034.8398,  val_mae:156.2465,  val_mse:42034.8398,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:7878.8892,  mae:49.5870,  mse:7878.8892,  val_loss:8195.6270,  val_mae:53.0977,  val_mse:8195.6270,  \n",
      "......................\n",
      "Epoch: 0, loss:213095.6406,  mae:344.8398,  mse:213095.6406,  val_loss:38577.7734,  val_mae:145.4905,  val_mse:38577.7734,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:8505.0439,  mae:50.6888,  mse:8505.0439,  val_loss:10129.0010,  val_mae:53.3184,  val_mse:10129.0010,  \n",
      ".....................................\n",
      "Epoch: 0, loss:205668.5156,  mae:339.5919,  mse:205668.5156,  val_loss:44122.9219,  val_mae:160.2603,  val_mse:44122.9219,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:7879.5703,  mae:48.8713,  mse:7879.5703,  val_loss:8347.5957,  val_mae:52.3722,  val_mse:8347.5957,  \n",
      "............................\n",
      "Epoch: 0, loss:208788.2500,  mae:343.3043,  mse:208788.2500,  val_loss:35312.5742,  val_mae:135.6670,  val_mse:35312.5742,  \n",
      ".........................................................................................\n",
      "Epoch: 0, loss:196634.4844,  mae:331.9260,  mse:196634.4844,  val_loss:36639.2617,  val_mae:138.9664,  val_mse:36639.2617,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:8426.8057,  mae:51.7453,  mse:8426.8057,  val_loss:8959.5869,  val_mae:50.8963,  val_mse:8959.5869,  \n",
      "......................................................."
     ]
    }
   ],
   "source": [
    "n_members = 5\n",
    "members = [fit_model(X_train, train) for _ in range(n_members)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: R2 0.928\n",
      "Model 2: R2 0.924\n",
      "Model 3: R2 0.926\n",
      "Model 4: R2 0.923\n",
      "Model 5: R2 0.922\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_members):\n",
    "    yhat = members[i].predict(X_test)\n",
    "    acc = r2_score(test, yhat)\n",
    "    print('Model %d: R2 %.3f' % (i+1, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal Weights Score: 0.931\n"
     ]
    }
   ],
   "source": [
    "weights = [1.0/n_members for _ in range(n_members)]\n",
    "score = evaluate_r2(members, weights, X_test, test)\n",
    "print('Equal Weights Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">[0. 0. 0. 0. 1.] 0.922\n",
      ">[0. 0. 0. 1. 0.] 0.923\n",
      ">[0.  0.  0.  0.5 0.5] 0.928\n",
      ">[0.         0.         0.         0.53333333 0.46666667] 0.928\n",
      ">[0.         0.         0.         0.52941176 0.47058824] 0.928\n",
      ">[0.         0.         0.         0.52631579 0.47368421] 0.928\n"
     ]
    }
   ],
   "source": [
    "with joblib.parallel_backend('dask'):\n",
    "    weights = grid_search(members, X_test, test, n_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Weights: [0.0, 0.0, 0.0, 0.5294117647058824, 0.47058823529411764], Score: 0.928\n"
     ]
    }
   ],
   "source": [
    "score = evaluate_r2(members, weights, X_test, test)\n",
    "print('Grid Search Weights: %s, Score: %.3f' % (weights, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
